{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anil951/YouTube-Video-Recommendation-for-Domain-Specific-Content/blob/main/lstm_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*sentiment analysis using LSTM*"
      ],
      "metadata": {
        "id": "E4kDJrHzs957"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout  # Add Dropout import\n",
        "from tensorflow.keras.optimizers import Adam  # Add Adam import\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your dataset\n",
        "file_path = r\"result.csv\"  # Replace with the path to your dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Assume you have two columns: 'Telugu_English' and 'Telugu'\n",
        "telugu_english_words = df['tenglish'].astype(str).tolist()\n",
        "telugu_words = df['telugu'].astype(str).tolist()\n",
        "\n",
        "# Tokenize the Telugu-English words\n",
        "tokenizer_telugu_english = Tokenizer()\n",
        "tokenizer_telugu_english.fit_on_texts(telugu_english_words)\n",
        "total_words_telugu_english = len(tokenizer_telugu_english.word_index) + 1\n",
        "\n",
        "# Tokenize the Telugu words\n",
        "tokenizer_telugu = Tokenizer()\n",
        "tokenizer_telugu.fit_on_texts(telugu_words)\n",
        "total_words_telugu = len(tokenizer_telugu.word_index) + 1\n",
        "\n",
        "# Encode the Telugu-English and Telugu words\n",
        "input_sequences_telugu_english = tokenizer_telugu_english.texts_to_sequences(telugu_english_words)\n",
        "input_sequences_telugu = tokenizer_telugu.texts_to_sequences(telugu_words)\n",
        "\n",
        "# Pad sequences to have consistent length\n",
        "max_sequence_length_telugu_english = max(len(seq) for seq in input_sequences_telugu_english)\n",
        "max_sequence_length_telugu = max(len(seq) for seq in input_sequences_telugu)\n",
        "\n",
        "padded_sequences_telugu_english = pad_sequences(input_sequences_telugu_english, maxlen=max_sequence_length_telugu_english, padding='post')\n",
        "padded_sequences_telugu = pad_sequences(input_sequences_telugu, maxlen=max_sequence_length_telugu, padding='post')\n",
        "\n",
        "# Encode Telugu words using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels_telugu = label_encoder.fit_transform(telugu_words)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences_telugu_english, labels_telugu, test_size=0.2, random_state=42)\n",
        "\n",
        "# Assuming labels_telugu is your encoded labels\n",
        "num_classes = len(np.unique(labels_telugu))\n",
        "\n",
        "# Build the LSTM model\n",
        "embedding_dim = 50\n",
        "lstm_units = 100\n",
        "\n",
        "# Increase model complexity with dropout\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=total_words_telugu_english, output_dim=embedding_dim, input_length=max_sequence_length_telugu_english))\n",
        "model.add(LSTM(units=lstm_units, return_sequences=True))\n",
        "model.add(Dropout(0.2))  # Adjust dropout rate as needed\n",
        "model.add(LSTM(units=lstm_units))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Experiment with different learning rates\n",
        "optimizer = Adam(learning_rate=0.001)  # Adjust the learning rate\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Increase the number of epochs\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Evaluation - Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "# # Save the model if needed\n",
        "# model.save('telugu_word_prediction_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo5fKoOUG7sg",
        "outputId": "653b3ac8-3f89-494e-b836-1845c1618e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "730/730 [==============================] - 88s 114ms/step - loss: 10.3801 - accuracy: 0.0000e+00 - val_loss: 10.5783 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "730/730 [==============================] - 79s 108ms/step - loss: 10.0558 - accuracy: 0.0000e+00 - val_loss: 10.8848 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "730/730 [==============================] - 79s 108ms/step - loss: 9.6955 - accuracy: 0.0000e+00 - val_loss: 11.5917 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "730/730 [==============================] - 80s 110ms/step - loss: 9.3416 - accuracy: 4.2847e-05 - val_loss: 13.1721 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "730/730 [==============================] - 80s 110ms/step - loss: 8.9735 - accuracy: 0.0000e+00 - val_loss: 14.8889 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "730/730 [==============================] - 83s 114ms/step - loss: 8.5844 - accuracy: 4.2847e-05 - val_loss: 15.9961 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "730/730 [==============================] - 78s 107ms/step - loss: 8.2216 - accuracy: 8.5693e-05 - val_loss: 16.8637 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "730/730 [==============================] - 79s 108ms/step - loss: 7.8919 - accuracy: 1.2854e-04 - val_loss: 17.6863 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "730/730 [==============================] - 77s 105ms/step - loss: 7.5794 - accuracy: 5.5701e-04 - val_loss: 17.7898 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "730/730 [==============================] - 80s 110ms/step - loss: 7.2819 - accuracy: 8.9978e-04 - val_loss: 17.5686 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "730/730 [==============================] - 94s 128ms/step - loss: 7.0116 - accuracy: 8.5693e-04 - val_loss: 17.9651 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "730/730 [==============================] - 87s 119ms/step - loss: 6.7379 - accuracy: 0.0018 - val_loss: 18.1699 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "730/730 [==============================] - 89s 122ms/step - loss: 6.4883 - accuracy: 0.0027 - val_loss: 18.4538 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "730/730 [==============================] - 87s 119ms/step - loss: 6.2542 - accuracy: 0.0047 - val_loss: 18.5097 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "730/730 [==============================] - 86s 118ms/step - loss: 6.0402 - accuracy: 0.0061 - val_loss: 18.6031 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "730/730 [==============================] - 86s 117ms/step - loss: 5.8394 - accuracy: 0.0079 - val_loss: 18.6507 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "730/730 [==============================] - 86s 118ms/step - loss: 5.6521 - accuracy: 0.0105 - val_loss: 18.6033 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "730/730 [==============================] - 88s 121ms/step - loss: 5.4726 - accuracy: 0.0114 - val_loss: 18.5890 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "730/730 [==============================] - 88s 121ms/step - loss: 5.2971 - accuracy: 0.0157 - val_loss: 18.6166 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "730/730 [==============================] - 89s 121ms/step - loss: 5.1475 - accuracy: 0.0206 - val_loss: 18.6059 - val_accuracy: 0.0000e+00\n",
            "183/183 [==============================] - 5s 25ms/step - loss: 18.6059 - accuracy: 0.0000e+00\n",
            "Evaluation - Loss: 18.605899810791016, Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_telugu_word(model, telugu_english_word, tokenizer_telugu_english, max_sequence_length_telugu_english, label_encoder):\n",
        "    # Tokenize the input Telugu-English word\n",
        "    input_sequence_telugu_english = tokenizer_telugu_english.texts_to_sequences([telugu_english_word])\n",
        "    padded_sequence_telugu_english = pad_sequences(input_sequence_telugu_english, maxlen=max_sequence_length_telugu_english, padding='post')\n",
        "\n",
        "    # Make the prediction\n",
        "    predicted_probs = model.predict(padded_sequence_telugu_english)\n",
        "\n",
        "    # Get the predicted class (Telugu word index)\n",
        "    predicted_class = np.argmax(predicted_probs)\n",
        "\n",
        "    # Decode the predicted class to the actual Telugu word\n",
        "    predicted_telugu_word = label_encoder.classes_[predicted_class]\n",
        "\n",
        "    return predicted_telugu_word\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'model', 'tokenizer_telugu_english', 'max_sequence_length_telugu_english', and 'label_encoder' are already defined and trained\n",
        "\n",
        "telugu_english_word_to_predict = 'annaya'  # Replace with the Telugu-English word you want to predict\n",
        "predicted_telugu_word = predict_telugu_word(model, telugu_english_word_to_predict, tokenizer_telugu_english, max_sequence_length_telugu_english, label_encoder)\n",
        "\n",
        "print(f\"Telugu-English Word: {telugu_english_word_to_predict}\")\n",
        "print(f\"Predicted Telugu Word: {predicted_telugu_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MrPqLm0HDOO",
        "outputId": "defe5853-20d4-4c7f-b0b0-41faeed1023f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Telugu-English Word: annaya\n",
            "Predicted Telugu Word: రాంగేయ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jrezkd9DG7vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "file_path = r\"abcd.csv\"  # Replace with the path to your dataset\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "Vgzt_7lNG72J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decontract(text):\n",
        "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'s\", \" is\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'t\", \" not\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'m\", \" am\", text)\n",
        "    return text\n",
        "\n",
        "#set of custom stop words\n",
        "stop_words= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
        "\n",
        "lemmatizer = nltk.WordNetLemmatizer()\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(review):\n",
        "    review = re.sub(r\"http\\S+\", \"\", review)             # removing website links\n",
        "    review = BeautifulSoup(review, 'lxml').get_text()   # removing html tags\n",
        "    review = decontract(review)                         # decontracting\n",
        "    review = re.sub(\"\\S*\\d\\S*\", \"\", review).strip()     # removing the words with numeric digits\n",
        "    review = re.sub('[^A-Za-z]+', ' ', review)          # removing non-word characters\n",
        "    review = review.lower()                             # converting to lower case\n",
        "    review = [word for word in review.split(\" \") if not word in stop_words] # removing stop words\n",
        "    review = [lemmatizer.lemmatize(token, \"v\") for token in review] #Lemmatization\n",
        "    review = \" \".join(review)\n",
        "    review.strip()\n",
        "    return review"
      ],
      "metadata": {
        "id": "nOeNwK8yS9LZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af69497-8a39-49b4-f52a-8e04c1bc373c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['up_text'] = df['text'].apply(lambda x: preprocess_text(x))\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2eklNI0H1Ua5",
        "outputId": "bef558bd-f6c5-4d3d-e855-5e0640771109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  sentiment  \\\n",
              "0                                        Love you sir!!          1   \n",
              "1     Another great explanation by Abdul sir. Thank ...          1   \n",
              "2     I had no idea what was going on in the first o...          1   \n",
              "3                                         great job!!!!          1   \n",
              "4                                      Thank you Sir !!          1   \n",
              "...                                                 ...        ...   \n",
              "4492  I got a little confused after watching this vi...         -1   \n",
              "4493  I got 18 points... I think most of the wrong a...         -1   \n",
              "4494  Why is 3a in the first block correct? A lingui...         -1   \n",
              "4495  Sometimes I feel like my English has really ad...         -1   \n",
              "4496  Thanks for exercise.  I need to listen much mo...         -1   \n",
              "\n",
              "                                                up_text  \n",
              "0                                             love sir   \n",
              "1       another great explanation abdul sir thank much   \n",
              "2            no idea go first one one clear everything   \n",
              "3                                            great job   \n",
              "4                                            thank sir   \n",
              "...                                                 ...  \n",
              "4492  get little confuse watch video exactly mean ba...  \n",
              "4493           get point think wrong answer forget say   \n",
              "4494  first block correct linguistic major refer lan...  \n",
              "4495  sometimes feel like english really advance eve...  \n",
              "4496         thank exercise need listen much bad score   \n",
              "\n",
              "[4497 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f907f80-97c8-4af9-ba54-dee8cd02b03d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>up_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Love you sir!!</td>\n",
              "      <td>1</td>\n",
              "      <td>love sir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Another great explanation by Abdul sir. Thank ...</td>\n",
              "      <td>1</td>\n",
              "      <td>another great explanation abdul sir thank much</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had no idea what was going on in the first o...</td>\n",
              "      <td>1</td>\n",
              "      <td>no idea go first one one clear everything</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>great job!!!!</td>\n",
              "      <td>1</td>\n",
              "      <td>great job</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thank you Sir !!</td>\n",
              "      <td>1</td>\n",
              "      <td>thank sir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4492</th>\n",
              "      <td>I got a little confused after watching this vi...</td>\n",
              "      <td>-1</td>\n",
              "      <td>get little confuse watch video exactly mean ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4493</th>\n",
              "      <td>I got 18 points... I think most of the wrong a...</td>\n",
              "      <td>-1</td>\n",
              "      <td>get point think wrong answer forget say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4494</th>\n",
              "      <td>Why is 3a in the first block correct? A lingui...</td>\n",
              "      <td>-1</td>\n",
              "      <td>first block correct linguistic major refer lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4495</th>\n",
              "      <td>Sometimes I feel like my English has really ad...</td>\n",
              "      <td>-1</td>\n",
              "      <td>sometimes feel like english really advance eve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4496</th>\n",
              "      <td>Thanks for exercise.  I need to listen much mo...</td>\n",
              "      <td>-1</td>\n",
              "      <td>thank exercise need listen much bad score</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4497 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f907f80-97c8-4af9-ba54-dee8cd02b03d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f907f80-97c8-4af9-ba54-dee8cd02b03d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f907f80-97c8-4af9-ba54-dee8cd02b03d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e759f74a-383b-4bdb-932d-9b94e79c4eb4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e759f74a-383b-4bdb-932d-9b94e79c4eb4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e759f74a-383b-4bdb-932d-9b94e79c4eb4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(df['text'].values)\n",
        "X = tokenizer.texts_to_sequences(df['text'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpMu0r2g2Xrd",
        "outputId": "65b42423-0ab3-4986-dc1d-b8ba1c0846a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 501, 128)          256000    \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 501, 128)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 196)               254800    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 394       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 511194 (1.95 MB)\n",
            "Trainable params: 511194 (1.95 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(df['sentiment']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7j5Mszm9Kcv",
        "outputId": "c1738766-5850-49b5-a9ff-d78ce22f9774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3012, 501) (3012, 2)\n",
            "(1485, 501) (1485, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming df is your DataFrame with 'text' and 'sentiment' columns\n",
        "\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(df['up_text'].values)\n",
        "X = tokenizer.texts_to_sequences(df['up_text'].values)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_fatures, embed_dim, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Use 'sigmoid' for binary classification\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "Y = df['sentiment'].values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)\n",
        "\n",
        "# batch_size = 32\n",
        "\n",
        "# Use tqdm to display a progress bar\n",
        "# for epoch in tqdm(range(7)):\n",
        "#     model.fit(X_train, Y_train, epochs=1, batch_size=batch_size, verbose=2)\n",
        "\n",
        "# Alternatively, you can use model.fit with validation data\n",
        "model.fit(X_train, Y_train, epochs=7, verbose=2, validation_data=(X_test, Y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1boMd2R-qSN",
        "outputId": "4d3ea796-0c25-4878-fd31-a29e1588532a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 234, 128)          256000    \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 234, 128)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 196)               254800    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 197       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 510997 (1.95 MB)\n",
            "Trainable params: 510997 (1.95 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "(3012, 234) (3012,)\n",
            "(1485, 234) (1485,)\n",
            "Epoch 1/7\n",
            "95/95 - 147s - loss: 0.3843 - accuracy: 0.9336 - val_loss: 0.3655 - val_accuracy: 0.9340 - 147s/epoch - 2s/step\n",
            "Epoch 2/7\n",
            "95/95 - 145s - loss: 0.1988 - accuracy: 0.9220 - val_loss: 0.2063 - val_accuracy: 0.9138 - 145s/epoch - 2s/step\n",
            "Epoch 3/7\n",
            "95/95 - 143s - loss: -3.2862e-02 - accuracy: 0.9021 - val_loss: 0.1286 - val_accuracy: 0.8976 - 143s/epoch - 2s/step\n",
            "Epoch 4/7\n",
            "95/95 - 146s - loss: -4.8724e-01 - accuracy: 0.9024 - val_loss: -3.0928e-02 - val_accuracy: 0.8714 - 146s/epoch - 2s/step\n",
            "Epoch 5/7\n",
            "95/95 - 141s - loss: -1.2952e+00 - accuracy: 0.9084 - val_loss: -2.4146e-01 - val_accuracy: 0.8936 - 141s/epoch - 1s/step\n",
            "Epoch 6/7\n",
            "95/95 - 141s - loss: -2.0265e+00 - accuracy: 0.9087 - val_loss: 0.1164 - val_accuracy: 0.8862 - 141s/epoch - 1s/step\n",
            "Epoch 7/7\n",
            "95/95 - 140s - loss: -1.0663e+00 - accuracy: 0.9200 - val_loss: 0.0253 - val_accuracy: 0.8680 - 140s/epoch - 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a740a0c3010>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, tokenizer, text):\n",
        "    # Tokenize and pad the input text\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=model.input_shape[1])\n",
        "\n",
        "    # Make predictions\n",
        "    probability = model.predict(padded_sequences)[0]\n",
        "\n",
        "    # Convert probability to sentiment label\n",
        "    sentiment_label = \"positive\" if probability > 0.5 else \"negative\"\n",
        "\n",
        "    # Convert sentiment label to target value\n",
        "    target_value = 1 if sentiment_label == \"positive\" else -1\n",
        "\n",
        "    return sentiment_label, target_value, probability\n",
        "\n",
        "# Example usage:\n",
        "new_text = \"this is a bad video\"\n",
        "sentiment, target_value, probability = predict_sentiment(model, tokenizer, new_text)\n",
        "\n",
        "print(f\"Predicted Sentiment: {sentiment}\")\n",
        "print(f\"Predicted Target Value: {target_value}\")\n",
        "print(f\"Probability: {probability}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u73LTGDgWpTM",
        "outputId": "c82ac20d-a034-4409-ec83-3c52de0b6c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 149ms/step\n",
            "Predicted Sentiment: negative\n",
            "Predicted Target Value: -1\n",
            "Probability: [3.5566947e-18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to the Colab file system\n",
        "model.save(\"sentiment_model.h5\")\n",
        "\n",
        "# Save the tokenizer\n",
        "with open(\"tokenizer.pkl\", \"wb\") as tokenizer_file:\n",
        "    pickle.dump(tokenizer, tokenizer_file)\n",
        "\n",
        "# Download the saved files to your local machine\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"sentiment_model.h5\")\n",
        "files.download(\"tokenizer.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8HvqIjyhjQQc",
        "outputId": "f6326d83-f35a-48dc-ac4a-b5aec54fccf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_55bfd0b2-0b4e-44e8-8274-73eda73d368c\", \"sentiment_model.h5\", 6172008)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fb9a846b-694b-4057-ac8b-28ab78c0efb2\", \"tokenizer.pkl\", 184123)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import pickle\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = load_model(\"/content/drive/MyDrive/yt/sentiment_model.h5\")\n",
        "\n",
        "# Load the tokenizer\n",
        "with open(\"/content/drive/MyDrive/yt/tokenizer.pkl\", \"rb\") as tokenizer_file:\n",
        "    loaded_tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "def predict_sentiment(model, tokenizer, text):\n",
        "    # Tokenize and pad the input text\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=model.input_shape[1])\n",
        "\n",
        "    # Make predictions\n",
        "    probability = model.predict(padded_sequences)[0]\n",
        "\n",
        "    # Convert probability to sentiment label\n",
        "    sentiment_label = \"positive\" if probability > 0.5 else \"negative\"\n",
        "\n",
        "    # Convert sentiment label to target value\n",
        "    target_value = 1 if sentiment_label == \"positive\" else -1\n",
        "\n",
        "    return sentiment_label, target_value, probability\n",
        "\n",
        "# Example usage:\n",
        "new_text = \"nice video\"\n",
        "sentiment, target_value, probability = predict_sentiment(loaded_model, loaded_tokenizer, new_text)\n",
        "\n",
        "print(f\"Predicted Sentiment: {sentiment}\")\n",
        "print(f\"Predicted Target Value: {target_value}\")\n",
        "print(f\"Probability: {probability}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KALA82pIlGnt",
        "outputId": "2857952e-4e57-45eb-f738-f86c33c56280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a7461ce65f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 386ms/step\n",
            "Predicted Sentiment: positive\n",
            "Predicted Target Value: 1\n",
            "Probability: [0.98200536]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}